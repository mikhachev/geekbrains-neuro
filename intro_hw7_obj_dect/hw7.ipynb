{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 7. Дектирование объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Сделайте краткий обзор какой-нибудь научной работы посвященной тому или иному алгоритму для object detection, который не рассматривался на уроке. Проведите анализ: Чем отличается выбранная вами на рассмотрение архитектура нейронной сети от других архитектур? В чем плюсы и минусы данной архитектуры? Какие могут возникнуть трудности при применении данной архитектуры на практике? \n",
    "    </li>\n",
    "    <li>* Ссылка на репозиторий с полным кодом для обучения ssd нейросети - https://github.com/sergeyveneckiy/ssd-tensorflow. Попробуйте улучшить точность ее работы и напишите отчет, что вы пробовали изменить в ее параметрах и как это отражалось на процессе обучения нейронной сети. \n",
    "        Обратите внимание! Мин. сист. требования для запуска данного проекта - это минимум 8 Gb ОЗУ. Если у вас недостаточно мощности компьютера, то вы можете просто изучить содержимое исходного кода и датасета данного проекта.</li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Real-Time Multi-Class Scene Understanding\n",
    "##  for Autonomous Driving Using Multiple Views\n",
    "\n",
    "#### Ke Chen\u0003, Ryan Oldja\u0003, Nikolai Smolyanskiy\u0003, Stan Birchfield\n",
    "#### Alexander Popov, David Wehr, Ibrahim Eden, Joachim Pehserl\n",
    "#### NVIDIA\n",
    "https://arxiv.org/pdf/2006.05518.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Автономное вождение требует восприятия актуальной в этот момент информации. Требуется в реальном моменте времени распознавать полосы движения, искривления дороги, сигнал светофора, препятствия, расстояние до автомобилей спереди, пешеходов и т.д.\n",
    "Исследователи предлагают методы использующие данные RGB картинки, данные лидара или их микс. Хотя как RGB распознавание довольно зрелая технология, она вносит заметные геометрические неточности. LIDAR решает эту проблему, но приносит другую - прямая обработка облака из 3D точек затруднительна. Один возможный путь здесь - взять 3D облако точек как воксельную сетку на вход DNN, но это все равно вычислительно дорого и имеет ошибки, другая проектировать это облако на вид птичьего глаза (Birds Eye View, BEV) и приментить 2D свертку, но здесь можно потерять сравнительно ценную информацию, например пешеходов из-за их малых размеров. В PIXOR используется 2D свертка на основе данных лидара, и проектируется на BEV тензор.  DNN вычисляет карты доверия объектов и регрессирует рамки объектов, размеры и ориентацию для каждого пикселя. Кластеризация используется для извлечения финальных позиций рамок. Такой метод довольно быстрый но может направильно определять объекты. Также VoxelNet , MV3D, PointNet, RangeNet++.\n",
    "\n",
    "В этой статье авторы пытаются обойти эти ограничения. Для облегчения распознавания пешеходов используется семантическая сегментация точек лидара. Применяется двухступенчатая многоплановая сеть, которая выполняет семантическую сегментацию проекции вида, а затем используется определение объектов через BEV. Используется 2D свертка, которая значительно быстрее 3D.\n",
    "На вход системы подается облако точек с обзором 360 град, которая проецируется сферически и сверху вниз(ортографическая проекция). На первом этапе извлекавется семантическая информация, которая делит сегменты изображения на классы: легковые автомобили, грузовики, пешеходы, велосипеды, дорогу, обочину и прочее.\n",
    "\n",
    "![lidar1.png](attachment:lidar1.png)\n",
    "\n",
    "\n",
    "Арахитектура похожа на FPN(feature pyramid network) по дизайну. Кодировщик состоит из 3 сверточных слоев с 64, 64 и 128 3х3 фильтрами, за ним следует три блока восприятия. Декодер возращает признаки назад к оригинальному разрешению через 3 блока развертки. За каждым блоком развертки стоит два сверточных слоя. Классификатор состоит из 3х3 сверточного слоя с размером 64 признака, затем 1х1 слой, который выдает 7-элементый вектор для пикселя. Каждый сверточный слой сопровождается батч нормализацией и ReLU активацией. \n",
    "Семантическ распознанный скан репроецируется на ортографическую проекцию. Вторая стадия архитектуры также шифратор-дешифратор неполносвязные с двумя центрами для классификации и регрессии рамок объектов. Используя вероятности классов(лучше чем сами классы), заставляет сеть выполнить более сложную и точную обработку (например пешеход или велосипед). Финальный выход состоит из массива 256х256 содержащего распределение классов вместе с другим массивом 256х256, содержащим расстояние до центра объекта, размеры и ориентацию. Этот этап натренирован с потерями, содержащими как фокальные потери, так и L1.  Кластеризующий алгоритм DBSCAN применяет на вход второй этап для определения объектов.\n",
    "Итого, представлена новая мультиклассовая система мгновенного определения авто и пешеходов по данным лидара. Благодаря своему простому подходу система работает быстрее другие подходов: 150 fps  на встроенном GPU.\n",
    "Авторы говорят о простоте подхода, объединяющим лучшее из разных подходов. Оба этапа могут обучаться независимо, например на датасетах SemanticKITTI и KITTI. Получена модель, способная достичь соревновательных результатов. Использовался Adam optimizer c lr= 0.0001. Обе стадии тренировались 40-50 эпох с батчем =4. \n",
    "В таблице приведены результаты сравнения с другими моделями, и получается что при сравнимой точности он будет быстрее. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"[lidar2.png]\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "![lidar2.png](attachment:lidar2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"[lidar4.jpg]\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "![lidar4.jpg](attachment:lidar4.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![lidar3.png](attachment:lidar3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "segmentation.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
